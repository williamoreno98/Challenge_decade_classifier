{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3adf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds fijadas (SEED=42). Python 3.12.3\n"
     ]
    }
   ],
   "source": [
    "# setup_repro_and_versions.py\n",
    "import os, random, numpy as np, platform\n",
    "import sklearn, pandas as pd, scipy, joblib\n",
    "\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "# Limitar threads BLAS (estabilidad y reproducibilidad)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "print(f\"Seeds fijadas (SEED={SEED}).\")\n",
    "print(\"POLICY: train solo con train.csv; eval solo para inferencia. Sin IDF transductivo ni pseudo-labels.\")\n",
    "print(\"Python   :\", platform.python_version())\n",
    "print(\"sklearn  :\", sklearn.__version__)\n",
    "print(\"numpy    :\", np.__version__)\n",
    "print(\"scipy    :\", scipy.__version__)\n",
    "print(\"pandas   :\", pd.__version__)\n",
    "print(\"joblib   :\", joblib.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d0581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV (5-fold) config final:\n",
      "Accuracy : 0.287648 ± 0.003078\n",
      "F1_macro: 0.276483 ± 0.003569\n",
      "\n",
      "Modelo final guardado en: tfidf_svc_word13md2_char25md4_C017_hash_w06_c14.joblib\n",
      "Meta escrita en model_meta.json\n"
     ]
    }
   ],
   "source": [
    "# train_final_S1.py\n",
    "import pandas as pd, numpy as np, unicodedata, re, json, pathlib, joblib\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "def clean_text(t: str) -> str:\n",
    "    t = unicodedata.normalize(\"NFKC\", str(t)).lower()\n",
    "    t = re.sub(r\"https?://\\S+|www\\.\\S+\", \" URL \", t)\n",
    "    t = re.sub(r\"\\d\", \"#\", t)          # seguimos hasheando dígitos\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "# 1) datos\n",
    "df = pd.read_csv(\"train.csv\").dropna(subset=[\"text\",\"decade\"]).reset_index(drop=True)\n",
    "df[\"decade\"] = df[\"decade\"].astype(int)\n",
    "df[\"text_clean\"] = df[\"text\"].apply(clean_text)\n",
    "X, y = df[\"text_clean\"].values, df[\"decade\"].values\n",
    "\n",
    "# 2) features (mejor S1: char (2,5), min_df=4; word igual)\n",
    "word_tfidf = TfidfVectorizer(\n",
    "    analyzer=\"word\", ngram_range=(1,3), min_df=2, max_df=0.9,\n",
    "    sublinear_tf=True, dtype=np.float32, strip_accents=\"unicode\", stop_words=None\n",
    ")\n",
    "char_tfidf = TfidfVectorizer(\n",
    "    analyzer=\"char\", ngram_range=(2,5), min_df=4, max_df=0.9,\n",
    "    sublinear_tf=True, dtype=np.float32\n",
    ")\n",
    "\n",
    "features = FeatureUnion(\n",
    "    [(\"word\", word_tfidf), (\"char\", char_tfidf)],\n",
    "    transformer_weights={\"word\":0.6, \"char\":1.4},\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "clf = LinearSVC(\n",
    "    C=0.19, class_weight=\"balanced\", max_iter=6000, random_state=SEED,\n",
    "    loss=\"squared_hinge\", multi_class=\"ovr\", tol=1e-4\n",
    ")\n",
    "\n",
    "pipe = Pipeline([(\"features\", features), (\"clf\", clf)])\n",
    "\n",
    "# 3) CV breve y determinista (5-fold)\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "scoring = {\"accuracy\":\"accuracy\", \"f1_macro\":make_scorer(f1_score, average=\"macro\", zero_division=0)}\n",
    "scores = cross_validate(pipe, X, y, cv=cv, scoring=scoring, n_jobs=1, return_train_score=False)\n",
    "print(\"\\nCV (5-fold) config S1:\")\n",
    "print(f\"Accuracy : {np.mean(scores['test_accuracy']):.6f} ± {np.std(scores['test_accuracy']):.6f}\")\n",
    "print(f\"F1_macro: {np.mean(scores['test_f1_macro']):.6f} ± {np.std(scores['test_f1_macro']):.6f}\")\n",
    "\n",
    "# 4) Entrena todo y guarda\n",
    "pipe.fit(X, y)\n",
    "OUT = \"tfidf_svc_word13md2_char25md4_C019_hash_w06_c14.joblib\"\n",
    "joblib.dump(pipe, OUT, compress=(\"xz\", 3))\n",
    "print(f\"\\nModelo final guardado en: {OUT}\")\n",
    "\n",
    "# 5) metadata enriquecida\n",
    "features_fitted = pipe.named_steps[\"features\"]\n",
    "word_vec = dict(features_fitted.transformer_list)[\"word\"]\n",
    "char_vec = dict(features_fitted.transformer_list)[\"char\"]\n",
    "\n",
    "meta = {\n",
    "  \"model_file\": OUT,\n",
    "  \"seed\": SEED,\n",
    "  \"transformer_weights\": {\"word\":0.6,\"char\":1.4},\n",
    "  \"word_tfidf\": {\n",
    "      \"analyzer\": \"word\", \"ngram_range\":[1,3], \"min_df\":2, \"max_df\":0.9,\n",
    "      \"sublinear_tf\": True, \"strip_accents\": \"unicode\", \"stop_words\": None,\n",
    "      \"vocab_size\": len(getattr(word_vec, \"vocabulary_\", {}))\n",
    "  },\n",
    "  \"char_tfidf\": {\n",
    "      \"analyzer\": \"char\", \"ngram_range\":[2,5], \"min_df\":4, \"max_df\":0.9,\n",
    "      \"sublinear_tf\": True, \"vocab_size\": len(getattr(char_vec, \"vocabulary_\", {}))\n",
    "  },\n",
    "  \"n_features_total\": int(features_fitted.transform(X[:1]).shape[1]),\n",
    "  \"train_rows\": int(len(df)),\n",
    "  \"class_distribution\": {int(k): int(v) for k, v in df[\"decade\"].value_counts().sort_index().items()},\n",
    "  \"clf\": {\"type\":\"LinearSVC\",\"C\":0.19,\"class_weight\":\"balanced\",\"max_iter\":6000,\"random_state\":SEED,\n",
    "          \"loss\":\"squared_hinge\",\"multi_class\":\"ovr\",\"tol\":1e-4},\n",
    "  \"cv\":{\"folds\":5,\"shuffle\":True,\"random_state\":SEED},\n",
    "  \"cv_results\":{\n",
    "    \"accuracy_mean\": float(np.mean(scores['test_accuracy'])),\n",
    "    \"accuracy_std\" : float(np.std(scores['test_accuracy'])),\n",
    "    \"f1_macro_mean\": float(np.mean(scores['test_f1_macro'])),\n",
    "    \"f1_macro_std\" : float(np.std(scores['test_f1_macro'])),\n",
    "  }\n",
    "}\n",
    "pathlib.Path(\"model_meta.json\").write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "print(\"Meta escrita en model_meta.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184f728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo de predicciones guardado en submission.csv\n"
     ]
    }
   ],
   "source": [
    "# predict_eval_final.py\n",
    "import pandas as pd, joblib, unicodedata, re\n",
    "\n",
    "MODEL_PATH = \"tfidf_svc_word13md2_char25md4_C019_hash_w06_c14.joblib\"\n",
    "pipe = joblib.load(MODEL_PATH)\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = unicodedata.normalize(\"NFKC\", str(text)).lower()\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \" URL \", text)\n",
    "    text = re.sub(r\"\\d\", \"#\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "df_eval = pd.read_csv(\"eval.csv\").dropna(subset=[\"id\",\"text\"]).reset_index(drop=True)\n",
    "df_eval[\"text_clean\"] = df_eval[\"text\"].apply(clean_text)\n",
    "\n",
    "preds = pipe.predict(df_eval[\"text_clean\"].values)\n",
    "pd.DataFrame({\"id\": df_eval[\"id\"], \"answer\": preds.astype(int)}).to_csv(\"submission.csv\", index=False)\n",
    "print(\"Archivo de predicciones guardado en submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
