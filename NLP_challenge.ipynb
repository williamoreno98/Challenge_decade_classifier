{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac77837a",
   "metadata": {},
   "source": [
    "### NLP challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "312c8cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01 -> Accuracy: 0.2382, F1_macro: 0.2099\n",
      "C=0.1 -> Accuracy: 0.2708, F1_macro: 0.2553\n",
      "C=1 -> Accuracy: 0.2678, F1_macro: 0.2609\n",
      "C=5 -> Accuracy: 0.2656, F1_macro: 0.2609\n",
      "C=10 -> Accuracy: 0.2646, F1_macro: 0.2600\n",
      "\n",
      "Mejor modelo encontrado:\n",
      "C=0.1 -> Accuracy=0.2708\n",
      "\n",
      "Reporte por clase:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         150       0.53      0.78      0.63       157\n",
      "         151       0.40      0.76      0.52       162\n",
      "         152       0.46      0.59      0.52       157\n",
      "         153       0.41      0.64      0.50       155\n",
      "         154       0.45      0.61      0.52       166\n",
      "         155       0.37      0.31      0.34       167\n",
      "         156       0.27      0.39      0.32       158\n",
      "         157       0.29      0.27      0.28       166\n",
      "         158       0.24      0.33      0.28       156\n",
      "         159       0.24      0.35      0.29       160\n",
      "         160       0.16      0.09      0.11       170\n",
      "         161       0.18      0.14      0.16       157\n",
      "         162       0.18      0.17      0.18       162\n",
      "         163       0.20      0.16      0.18       166\n",
      "         164       0.23      0.17      0.20       161\n",
      "         165       0.12      0.09      0.10       163\n",
      "         166       0.12      0.05      0.07       156\n",
      "         167       0.22      0.18      0.20       166\n",
      "         168       0.23      0.18      0.20       164\n",
      "         169       0.18      0.16      0.17       154\n",
      "         170       0.21      0.28      0.24       167\n",
      "         171       0.20      0.23      0.22       163\n",
      "         172       0.20      0.20      0.20       169\n",
      "         173       0.29      0.26      0.28       160\n",
      "         174       0.26      0.17      0.21       161\n",
      "         175       0.22      0.15      0.18       163\n",
      "         176       0.22      0.23      0.23       151\n",
      "         177       0.20      0.18      0.19       156\n",
      "         178       0.28      0.28      0.28       166\n",
      "         179       0.24      0.23      0.24       162\n",
      "         180       0.24      0.19      0.22       165\n",
      "         181       0.29      0.37      0.33       159\n",
      "         182       0.31      0.25      0.28       162\n",
      "         183       0.20      0.11      0.14       159\n",
      "         184       0.26      0.22      0.24       160\n",
      "         185       0.16      0.11      0.13       161\n",
      "         186       0.12      0.09      0.10       155\n",
      "         187       0.21      0.19      0.20       157\n",
      "         188       0.26      0.40      0.31       162\n",
      "\n",
      "    accuracy                           0.27      6281\n",
      "   macro avg       0.25      0.27      0.26      6281\n",
      "weighted avg       0.25      0.27      0.25      6281\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# baseline_simple.py\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "import joblib\n",
    "import re\n",
    "import unicodedata\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ---------- 1) Cargar datos ----------\n",
    "df = pd.read_csv(\"train.csv\")   # debe tener columnas \"text\" y \"decade\"\n",
    "df = df.dropna(subset=[\"text\", \"decade\"]).reset_index(drop=True)\n",
    "\n",
    "# Si decade viene como string o necesita conversión, conviértelo a int:\n",
    "# (según tu enunciado, 202 -> 2020; aquí mantendremos la etiqueta tal como está para el modelo)\n",
    "df['decade'] = df['decade'].astype(int)\n",
    "\n",
    "# ---------- 2) Preprocesamiento simple ----------\n",
    "\n",
    "def clean_text(text: str) -> str:\n",
    "    text = unicodedata.normalize(\"NFKC\", str(text))\n",
    "    # 2. Pasar a minúsculas\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "\n",
    "df['text_clean'] = df['text'].apply(clean_text)\n",
    "\n",
    "# ---------- 3) Train / Test split (estratificado) ----------\n",
    "X = df['text_clean'].values\n",
    "y = df['decade'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# ---------- 4) Pipeline (TF-IDF word + char) + LogisticRegression ----------\n",
    "word_tfidf = TfidfVectorizer(ngram_range=(1,2), analyzer='word', max_df=0.9, min_df=2)\n",
    "char_tfidf = TfidfVectorizer(ngram_range=(3,5), analyzer='char', max_df=0.9, min_df=2)\n",
    "\n",
    "# Hiperparámetros a probar\n",
    "param_grid = {\n",
    "    'clf__C': [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Valores de C a probar\n",
    "C_values = [0.01, 0.1, 1, 5, 10]\n",
    "\n",
    "best_acc = 0\n",
    "best_model = None\n",
    "best_C = None\n",
    "\n",
    "for c in C_values:\n",
    "    clf = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            ('word', word_tfidf),\n",
    "            ('char', char_tfidf)\n",
    "        ])),\n",
    "        ('clf', LinearSVC(class_weight='balanced', C=c, random_state=42, max_iter=5000))\n",
    "    ])\n",
    "\n",
    "    # Entrenar en train\n",
    "    clf.fit(X_train, y_train)\n",
    "    # Evaluar en test\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "    print(f\"C={c} -> Accuracy: {acc:.4f}, F1_macro: {f1:.4f}\")\n",
    "\n",
    "    # Guardar el mejor\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_model = clf\n",
    "        best_C = c\n",
    "\n",
    "print(\"\\nMejor modelo encontrado:\")\n",
    "print(f\"C={best_C} -> Accuracy={best_acc:.4f}\")\n",
    "\n",
    "# Reporte detallado\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"\\nReporte por clase:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acc8577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_simple.py\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import unicodedata\n",
    "\n",
    "# ---------- 1) Cargar datos ----------\n",
    "df = pd.read_csv(\"train.csv\")   # debe tener columnas \"text\" y \"decade\"\n",
    "df = df.dropna(subset=[\"text\", \"decade\"]).reset_index(drop=True)\n",
    "\n",
    "# Convertir decade a int (si viene como string)\n",
    "df['decade'] = df['decade'].astype(int)\n",
    "\n",
    "# ---------- 2) Preprocesamiento simple ----------\n",
    "def clean_text(text: str) -> str:\n",
    "    text = unicodedata.normalize(\"NFKC\", str(text))\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df['text_clean'] = df['text'].apply(clean_text)\n",
    "\n",
    "X = df['text_clean'].values\n",
    "y = df['decade'].values\n",
    "\n",
    "# ---------- 3) Pipeline (TF-IDF word + char) + LogisticRegression ----------\n",
    "word_tfidf = TfidfVectorizer(ngram_range=(1,2), analyzer='word', max_df=0.9, min_df=2)\n",
    "char_tfidf = TfidfVectorizer(ngram_range=(3,5), analyzer='char', max_df=0.9, min_df=2)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('features', FeatureUnion([('word', word_tfidf), ('char', char_tfidf)])),\n",
    "    ('clf', LinearSVC(class_weight='balanced', C=0.1, random_state=42, max_iter=5000))\n",
    "])\n",
    "\n",
    "# ---------- 4) Entrenar con TODO ----------\n",
    "pipeline.fit(X, y)\n",
    "\n",
    "# ---------- 5) Guardar el modelo entrenado ----------\n",
    "joblib.dump(pipeline, \"baseline_tfidf_logreg_full.joblib\")\n",
    "print(\"Modelo guardado en baseline_tfidf_logreg_full.joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "332d2492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo de predicciones guardado en submission.csv\n"
     ]
    }
   ],
   "source": [
    "# predict_eval.py\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import unicodedata\n",
    "\n",
    "# ---------- 1) Cargar modelo entrenado ----------\n",
    "pipeline = joblib.load(\"baseline_tfidf_logreg_full.joblib\")\n",
    "\n",
    "# ---------- 2) Cargar datos de evaluación ----------\n",
    "df_eval = pd.read_csv(\"eval.csv\")  # columnas: id,text\n",
    "\n",
    "# ---------- 3) Preprocesamiento (mismo que en entrenamiento) ----------\n",
    "def clean_text(text: str) -> str:\n",
    "    text = unicodedata.normalize(\"NFKC\", str(text))\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df_eval['text_clean'] = df_eval['text'].apply(clean_text)\n",
    "\n",
    "# ---------- 4) Predecir ----------\n",
    "X_eval = df_eval['text_clean'].values\n",
    "preds = pipeline.predict(X_eval)\n",
    "\n",
    "# ---------- 5) Guardar archivo de respuesta ----------\n",
    "df_out = pd.DataFrame({\n",
    "    \"id\": df_eval[\"id\"],\n",
    "    \"answer\": preds\n",
    "})\n",
    "\n",
    "df_out.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Archivo de predicciones guardado en submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
