{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e3adf2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds fijadas (SEED=42).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# Semillas y límites de hilos p/ reproducibilidad y estabilidad (especialmente en Windows)\n",
    "SEED = 42\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "print(f\"Seeds fijadas (SEED={SEED}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7184f728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Desempeño estimado (5-fold CV) del setup estático:\n",
      "Accuracy : 0.278827 ± 0.003821\n",
      "F1_macro: 0.264477 ± 0.003627\n"
     ]
    }
   ],
   "source": [
    "# train_static_svm.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score\n",
    "import joblib\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "# ---------- 1) Cargar datos ----------\n",
    "df = pd.read_csv(\"train.csv\")  # columnas: text, decade\n",
    "df = df.dropna(subset=[\"text\", \"decade\"]).reset_index(drop=True)\n",
    "df[\"decade\"] = df[\"decade\"].astype(int)\n",
    "\n",
    "# ---------- 2) Preprocesamiento coherente ----------\n",
    "def clean_text(t: str) -> str:\n",
    "    t = unicodedata.normalize(\"NFKC\", str(t))\n",
    "    return t.lower()\n",
    "\n",
    "df[\"text_clean\"] = df[\"text\"].apply(clean_text)\n",
    "X = df[\"text_clean\"].values\n",
    "y = df[\"decade\"].values\n",
    "\n",
    "# ---------- 3) Features estáticos (GANADOR) ----------\n",
    "word_tfidf = TfidfVectorizer(\n",
    "    analyzer=\"word\",\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=1,              # <- actualizado\n",
    "    max_df=0.9,\n",
    "    sublinear_tf=True,\n",
    "    dtype=np.float32,\n",
    "    strip_accents=None,\n",
    "    stop_words=None\n",
    ")\n",
    "char_tfidf = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    ngram_range=(3, 5),\n",
    "    min_df=3,              # <- actualizado\n",
    "    max_df=0.9,\n",
    "    sublinear_tf=True,\n",
    "    dtype=np.float32\n",
    ")\n",
    "\n",
    "features = FeatureUnion(\n",
    "    transformer_list=[(\"word\", word_tfidf), (\"char\", char_tfidf)],\n",
    "    transformer_weights={\"word\": 0.7, \"char\": 1.3},   # <- actualizado\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# ---------- 4) Clasificador estático (GANADOR) ----------\n",
    "clf = LinearSVC(\n",
    "    C=0.12,                       # <- actualizado\n",
    "    class_weight=\"balanced\",\n",
    "    max_iter=5000,\n",
    "    random_state=SEED\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"features\", features),\n",
    "    (\"clf\", clf)\n",
    "])\n",
    "\n",
    "# ---------- 5) Validación cruzada (determinista, ligera) ----------\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "scoring = {\n",
    "    \"accuracy\": make_scorer(accuracy_score),\n",
    "    \"f1_macro\": make_scorer(f1_score, average=\"macro\", zero_division=0)\n",
    "}\n",
    "\n",
    "scores = cross_validate(\n",
    "    pipe, X, y, cv=cv,\n",
    "    scoring=scoring,\n",
    "    n_jobs=1,                # reproducible/estable en Windows\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "print(\"\\nDesempeño estimado (5-fold CV) del setup estático:\")\n",
    "print(f\"Accuracy : {np.mean(scores['test_accuracy']):.6f} ± {np.std(scores['test_accuracy']):.6f}\")\n",
    "print(f\"F1_macro: {np.mean(scores['test_f1_macro']):.6f} ± {np.std(scores['test_f1_macro']):.6f}\")\n",
    "\n",
    "# ---------- 6) Reentrenar con TODO y guardar ----------\n",
    "pipe.fit(X, y)\n",
    "OUTFILE = \"baseline_tfidf_logreg_full.joblib\"  # mantiene el nombre esperado por predict_eval.py\n",
    "joblib.dump(pipe, OUTFILE)\n",
    "print(f\"\\nModelo final guardado en: {OUTFILE}\")\n",
    "\n",
    "# ---------- 7) Guardar metadatos (con versiones del entorno) ----------\n",
    "meta = {\n",
    "    \"model_file\": OUTFILE,\n",
    "    \"seed\": SEED,\n",
    "    \"transformer_weights\": {\"word\": 0.7, \"char\": 1.3},\n",
    "    \"word_tfidf\": {\"ngram_range\": (1,2), \"min_df\": 1, \"max_df\": 0.9, \"sublinear_tf\": True, \"strip_accents\": None},\n",
    "    \"char_tfidf\": {\"ngram_range\": (3,5), \"min_df\": 3, \"max_df\": 0.9, \"sublinear_tf\": True},\n",
    "    \"clf\": {\"type\": \"LinearSVC\", \"C\": 0.12, \"class_weight\": \"balanced\", \"max_iter\": 5000, \"random_state\": SEED},\n",
    "    \"cv\": {\"folds\": 5, \"shuffle\": True, \"random_state\": SEED},\n",
    "    \"cv_results\": {\n",
    "        \"accuracy_mean\": float(np.mean(scores['test_accuracy'])),\n",
    "        \"accuracy_std\": float(np.std(scores['test_accuracy'])),\n",
    "        \"f1_macro_mean\": float(np.mean(scores['test_f1_macro'])),\n",
    "        \"f1_macro_std\": float(np.std(scores['test_f1_macro'])),\n",
    "    }\n",
    "}\n",
    "\n",
    "# Capturar versiones reales del entorno\n",
    "try:\n",
    "    import importlib.metadata as md\n",
    "    versions = {p: md.version(p) for p in [\"scikit-learn\",\"numpy\",\"scipy\",\"pandas\",\"joblib\"]}\n",
    "except Exception:\n",
    "    versions = {}\n",
    "meta[\"versions\"] = versions\n",
    "\n",
    "import json, pathlib\n",
    "pathlib.Path(\"model_meta.json\").write_text(json.dumps(meta, indent=2, ensure_ascii=False))\n",
    "print(\"Meta guardado en model_meta.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f748fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo de predicciones guardado en submission.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import unicodedata\n",
    "\n",
    "# 1) Cargar modelo entrenado\n",
    "pipeline = joblib.load(\"baseline_tfidf_logreg_full.joblib\")\n",
    "\n",
    "# 2) Cargar datos de evaluación\n",
    "df_eval = pd.read_csv(\"eval.csv\")  # columnas: id, text\n",
    "\n",
    "# 3) Preprocesamiento consistente\n",
    "def clean_text(text: str) -> str:\n",
    "    text = unicodedata.normalize(\"NFKC\", str(text))\n",
    "    return text.lower()\n",
    "\n",
    "df_eval[\"text_clean\"] = df_eval[\"text\"].apply(clean_text)\n",
    "\n",
    "# 4) Predecir\n",
    "X_eval = df_eval[\"text_clean\"].values\n",
    "preds = pipeline.predict(X_eval)\n",
    "\n",
    "# 5) Guardar submission (aseguramos ints nativos)\n",
    "df_out = pd.DataFrame({\"id\": df_eval[\"id\"], \"answer\": preds})\n",
    "df_out[\"answer\"] = df_out[\"answer\"].astype(int)\n",
    "df_out.to_csv(\"submission.csv\", index=False)\n",
    "print(\"Archivo de predicciones guardado en submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
